다음은 AI 관련 아티클 링크들을 논리적인 주제별 구조로 정리한 목록입니다.

---

# **AI 관련 자료 정리**

## **1. 면접 대비 (Interview Preparation)**
- [Datascience interview questions](https://github.com/zzsza/Datascience-Interview-Questions)
- [Data scientist interview questions](https://devinterview.io/questions/machine-learning-and-data-science/data-scientist-interview-questions/)
- [Data science interview questions and answers](https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers)
- [Machine learning and Deep learning interview questions](https://yongwookha.github.io/MachineLearning/2021-01-29-interview-question)
- [Machine learning interview(김태훈)](https://docs.google.com/document/d/10bJK8S4T7sBIP-pzdQm9xRpW0HcLsrh6D047pE_kFE8/edit#heading=h.op9mv2ffig8x)
- [AI tech interview](https://github.com/boost-devs/ai-tech-interview?utm_source=chatgpt.com)

---

## **2. AI 개론 및 최신 연구 동향**
### **(1) AI 일반 개론**
- [앤드류 응(2022). 위대한 수업. EBS.](https://youtu.be/kgXlcJDHLJ0?feature=shared)
- [앤드류 응(2024). AI의 기회 및 위험. 과학기술정부통신부.](https://youtu.be/693rBSMHFLY?feature=shared)

### **(2) 추천 시스템 연구**
- [오진호, 유환조 (2014). 추천 시스템 연구 논문](https://drive.google.com/file/d/1XDjFtieehEijR_XeL1hEmK42f1xZB8j7/view?usp=sharing)
- [송경우, 문일철 (2021). 추천시스템 최근 연구 동향](https://drive.google.com/file/d/13IuvO410e6mhI7REqPDk2vBestGtNml9/view?usp=sharing)

---

## **3. 딥러닝 학습 자료**
### **(1) 학습 자료**
- [뉴욕대학교 조경현 교수님 관련 만화](https://wedatalab.tistory.com/126)
- [Deep learning 전반적 개요](https://atcold.github.io/NYU-DLSP21/)
- [스탠포드 CS231n](https://cs231n.github.io/)
- [Deep learning Method(Chip Huyen)](https://huyenchip.com/blog/)

### **(2) AI 연구 방향 및 산업적 활용**
- [AI 기술들의 활용 사례 및 연구 방향](https://davincilabs.ai/blog/?q=YToxOntzOjEyOiJrZXl3b3JkX3R5cGUiO3M6MzoiYWxsIjt9&bmode=view&idx=11155573&t=board)
- [연구 방향과 좋은 연구에 대한 글](https://www.linkedin.com/posts/abeirami_in-todays-publication-culture-most-authors-activity-7274035029259829248-rGL_/)

---

## **4. 모델 성능 및 이론적 개념**
- [딥러닝 성능 고도화 방법 요약](https://www.youtube.com/watch?v=EehRcPo1M-Q&t=35s)
- [편향-분산 관계 및 이중 하강 (double descent) 현상](https://openai.com/index/deep-double-descent/)
- [MIT Neural Nets, Back Propagation 강의](https://www.youtube.com/watch?v=q0pm3BrIUFo)
- [구글 GATO: 트랜스포머 기반 Generalist Agent](https://www.youtube.com/watch?v=36-14yZkJgs)

---

## **5. PyTorch 및 머신러닝 실습 자료**
- [PyTorch 기본 문법 및 코드 snippets](https://gaussian37.github.io/dl-pytorch-snippets/)
- [Dive into Deep Learning (PyTorch 기반 딥러닝 교재)](https://d2l.ai/)
- [기초 선형대수학 정리](https://angeloyeo.github.io/2020/09/07/basic_vector_operation.html)
- [PyTorch 2.x vs 1.x 비교](https://wandb.ai/capecape/pt2/reports/Why-You-Should-Upgrade-Your-Code-to-PyTorch-2-0--VmlldzozODUyMzcw)
  - [Overview](https://pytorch.org/get-started/pytorch-2.0/)
  - [Blog post](https://pytorch.org/blog/pytorch-2.0-release/)

---

## **6. 데이터셋 및 연구 자원**
- [AI-Hub & 서울특별시 빅데이터 캠퍼스](https://www.aihub.or.kr/)
- [Awesome Public Dataset](https://github.com/awesomedata/awesome-public-datasets)

---

## **7. 딥러닝 모델 연구 및 논문 정리**
- [Backbones-Review 논문 (Feature extraction 비교)](https://arxiv.org/abs/2206.08016)
- [백본 네트워크 구조 상세분석 블로그](https://velog.io/@xpelqpdj0422/Going-DeeperCV1.-%EB%B0%B1%EB%B3%B8-%EB%84%A4%ED%8[…]ED%81%AC-%EA%B5%AC%EC%A1%B0-%EC%83%81%EC%84%B8%EB%B6%84%EC%84%9D)

---

## **8. 객체 검출 (Object Detection)**
- **Zero-shot Object Detection**
  - [Hugging Face 관련 자료](https://huggingface.co/docs/transformers/ko/tasks/zero_shot_object_detection)
  - [논문 및 관련 블로그](https://paperswithcode.com/task/zero-shot-object-detection)
- **Transformer 기반 Object Detection**
  - [DETR 논문](https://arxiv.org/abs/2005.12872)
  - [Swin Transformer for Object Detection 논문](https://arxiv.org/abs/2103.14030)

---

## **9. 시맨틱 분할 (Semantic Segmentation)**
- **DeepLabv3 논문**: [논문 링크](https://arxiv.org/abs/1802.02611)
- **SETR 논문**: [논문 링크](https://arxiv.org/abs/2012.15840)
- [Semantic Segmentation 관련 모델 정리](https://paperswithcode.com/task/semantic-segmentation)

---

## **10. 실험 관리 및 MLOps**
- [MLflow 공식 홈페이지](https://mlflow.org/)
- [Weights & Biases (wandb) 실험 관리](https://wandb.ai/site/ko/)
- [PyTorch Lightning (딥러닝 모델 실험 자동화)](https://lightning.ai/docs/pytorch/stable/)
- [Hydra Config 활용](https://hydra.cc/docs/intro/)

---

## **11. LLM 관련 최적화 기술**
- **Flash Attention**
  - [Flash Attention 2 개요](https://taewan2002.medium.com/성능-최적화를-위한-flash-attention-2-41a345808005)
- **vLLM (LLM 서빙 최적화)**
  - [공식 문서](https://docs.vllm.ai/en/latest/index.html)
  - [활용 예제](https://lsjsj92.tistory.com/668)
- **AirLLM (저사양 GPU에서 LLM 실행)**
  - [공식 문서](https://huggingface.co/blog/lyogavin/airllm)

---

## **12. Hugging Face 및 언어모델 학습**
- [Hugging Face Trainer 모듈](https://huggingface.co/docs/transformers/main/en/main_classes/trainer)
- [Wandb + LLM 평가](https://learn.deeplearning.ai/courses/evaluating-debugging-generative-ai/lesson/5/llm-evaluation-and-tracing-with-w%26b)
- [Unsloth (LLM 메모리 최적화)](https://github.com/unslothai/unsloth)

### Linearly Mapping from Image to Text Space (LiT)  
[Paper Link](https://arxiv.org/abs/2209.15162)

#### 주요 내용  
- 기존 **Contrastive Image-Text Pretraining (CLIP)** 방식과 달리 **이미지에서 텍스트 공간으로 선형 매핑(Linearly Mapping)** 수행  
- 사전 훈련된 강력한 텍스트 인코더(예: T5)를 고정하고, **이미지 인코더만 학습**하여 효율적 훈련 가능  
- **멀티모달 표현학습**에서 텍스트 표현이 강력할수록 성능이 향상됨을 증명  
- 기존 CLIP과 비교하여 **텍스트와의 정렬 성능이 개선**되면서도 학습 비용 감소  

#### 핵심 기여  
- **텍스트 인코더를 고정**하여 훈련 비용 절감  
- **이미지에서 텍스트 공간으로 직접 매핑하는 방식**으로 학습 간소화  
- CLIP 대비 성능 향상 (Image-Text Retrieval, Zero-shot Transfer 등)  
- **멀티모달 학습에서 텍스트 표현의 중요성 강조**  

---

### BLIP (Bootstrapped Language-Image Pretraining)  
[BLIP 개요](https://medium.com/@researchgraph/what-is-blip-b83d73a03ec5)

#### 주요 특징  
- **자연어 이해와 이미지 캡셔닝을 결합한 멀티모달 모델**  
- **이미지-텍스트 데이터 활용 방법 개선**  
  - 웹에서 수집한 노이즈 많은 데이터를 효과적으로 정제  
- **이미지-텍스트 정렬 (Image-Text Alignment) 강화**  
- 다양한 멀티모달 태스크 (이미지 캡셔닝, VQA, 이미지-텍스트 검색)에서 강력한 성능  

#### 핵심 기여  
- **자기 지도 학습 + 약한 지도 학습 조합**으로 성능 개선  
- CLIP과 달리, **더 높은 품질의 이미지-텍스트 정렬 데이터 학습 가능**  
- 다양한 다운스트림 태스크에서 강력한 성능  

---

### CoCa (Contrastive Captioners)  
[CoCa 개요](https://sh-tsang.medium.com/brief-review-coca-contrastive-captioners-are-image-text-foundation-models-9f757746e459)

#### 주요 특징  
- **Contrastive Learning + Captioning을 결합한 멀티모달 모델**  
- CLIP과 유사한 **이미지-텍스트 대조 학습** 수행  
- 이미지 캡셔닝을 위한 **언어 모델링 기법 결합**  
- **Zero-shot 및 Few-shot 성능 향상**  

#### 핵심 기여  
- **대조 학습과 캡셔닝을 동시에 학습**하여 멀티모달 표현력 향상  
- 이미지-텍스트 정렬을 강화하면서도 **텍스트 생성 능력 보유**  
- 다양한 비전-언어 태스크에서 SOTA 성능 달성  

---

### 비교 요약  
| 모델  | 주요 특징 | 장점 | 단점 |
|------|--------|------|------|
| **LiT** | 이미지에서 텍스트 공간으로 선형 매핑 | 기존 CLIP 대비 성능 향상, 훈련 비용 절감 | 텍스트 표현력이 중요하므로, 약한 텍스트 인코더 사용 시 성능 저하 가능 |
| **BLIP** | 자연어 이해 + 이미지 캡셔닝 | 웹 데이터 정제, 멀티모달 정렬 최적화 | 훈련 데이터 품질이 중요 |
| **CoCa** | 대조 학습 + 캡셔닝 결합 | Zero-shot 성능 강함, 생성 및 이해 능력 겸비 | 모델 크기 증가, 학습 복잡성 증가 |

- [Imagic: Text-Based Real Image Editing with Diffusion Models](https://arxiv.org/pdf/2210.09276)